# DSCI6004-FinalProject

## Multimodal Sarcasm Detection
## Final Project for the Natural Language Processing Course - University of New Haven - Fall 2024
### Jafar Vohra

**Introduction:**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This project explores advanced methods for sarcasm detection using multimodal data, combining textual, visual, and audio information to improve the accuracy and robustness of sarcasm classification models.

**Task 1: Visual-Textual Sarcasm Detection:**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This task focuses on detecting sarcasm using paired text and images as input. The approach incorporates modern deep learning architectures, such as transformers and feed-forward neural networks, to learn the relationships between textual and visual cues that indicate sarcastic intent.

**Task 2: Audio-Visual & Textual Sarcasm Detection:**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This task extends the first by adding audio data, recognizing that sarcasm can also be expressed through vocal tone and facial expressions. The model uses multimodal input to detect sarcasm across diverse communication channels and improve the understanding of sarcasm in dynamic, real-time environments.

**Project Report:** 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The project report has a detailed description of the working and execution of the project along with the explanation of the code. 

**Project Presentation:**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The presentation video of this project is available @ https://youtu.be/NbTxlLd392c
